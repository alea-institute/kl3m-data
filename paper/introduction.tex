\section{Introduction}
Over the past decade, there has been significant progress on general-purpose language modeling driven by the application of neural based methods \cite{rumelhart1986learning}\cite{hopfield1982neural} to corpora of increasing larger scales.\cite{brown2020language}\cite{dubey2024llama}\cite{guo2025deepseek}  Leading large language models (LLMs) have displayed significant progress on a range of challenging real-world tasks.\cite{goh2025gpt}\cite{dell2023navigating}\cite{katz2024gpt}\cite{brin2023comparing}

While fewer and fewer question the technical progress of these models' capabilities, the training and use of large language models, however, is not without controversy.   Indeed, there are an emerging range of questions associated with the development of generative A.I. technology.  These objections vary and cover a range of topics including the `openness' of the model creation process and the `toxicity' of the subsequent outputs.\cite{liesenfeld2024rethinking}\cite{longpre2024pretrainer}\cite{bommasani2024foundation}  While these are certainly important issues, far less attention, by contrast, has been paid to use training data collected at scale without respect to the moral and legal rights of its creators.  

Virtually all existing LLMs rely upon the large-scale collection and use of materials that are subject to copyright. Despite various clever efforts to ameliorate such issues at both training \cite{minsilo2024} and inference time \cite{golatkar2024cpr}\cite{ippolito2023preventing}\cite{flemings2024differentially} many leading models can still engage in relatively high levels of potentially infringing behavior.\cite{chen2024copybench}     

There is still the open question of whether notions ``fair use" or ``fair dealing" might serve as a legal defense to this otherwise problematic behavior.\cite{henderson2023foundation}\cite{sag2024fairness}  However, it is worth noting that while ``[M]ore than forty countries with over one-third of the worldâ€™s population have fair use or fair dealing provisions in their copyright laws,"\cite{band2013fair} the interpretation of such principles can vary significantly across jurisdictions.\footnote{It is worth noting that although some model providers are offering ``fair use'' as a defense to their data collection practices, many such organizations are also inherently acknowledging the property rights of creators by entering into licensing deals.} 

In light of this reality, we set out on an alternative path - one that is rooted in a rigorous data collection and curation processes designed to respect traditional legal and ethical frameworks.  In this paper, we present the Kelvin Legal Large Language Model (KL3M) dataset, tokenizer, software, and APIs. These assets, open-sourced and maintained by the ALEA Institute,\footnote{\textit{See} Institute for the Advancement of Legal and Ethical AI (ALEA Institute) \url{https://aleainstitute.ai/} } represent one of the largest collections of pretraining and supervised fine-tuning data unencumbered by copyright risk.  We outline a framework for determining permissibility of content usage that can be employed by anyone who wants to gather or audit training data for model training or fine-tuning. In addition, we enhance the data provenance visibility of the KL3M dataset by providing Dublin Core metadata for all data in the dataset.\cite{park2009dublin}

%Thus, in the following sections, we will detail our data sources, collection process, preprocessing methods, and the characteristics of the resulting dataset. We will also discuss the implications of our work for future A.I. development in the context of the broader legal and ethical landscape.



%Our approach aims to circumvent the need for reliance on fair use arguments by ensuring all data in the KL3M dataset is either in the public domain or explicitly licensed for unrestricted use.

%In light of this reality, we set out on an alternative research agenda - one that is rooted in legal and ethical practices that are free of doubt. Our primary contribution to a space already saturated with datasets is the research into and development of a path that is free of reliance on the "fair use" argument that is often relied upon for model training.


%With over 30 copyright lawsuits against AI companies currently in progress in the US alone, the need for legal precedent on the matter of copyright infringement and model training is clear. The outcome of these cases will likely establish whether the argument for "fair use" in model training is a viable one. 

%However, regardless of what one believes about the legal and ethical questions underlying this uncertainty, there is no denying the existence of the many lawsuits and investigations ongoing in major jurisdictions.
